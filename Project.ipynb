{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a project that performs various binary classification methods on a social science dataset you may want to focus on data munging, method selection, method evaluation, feature extraction, and presentation of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of stock raise/fall using state-of-the-art Machine Learning and Deep Learning methods.\n",
    "\n",
    "## STA208 Final project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample outline:\n",
    "\n",
    "1. Introduction\n",
    "   - stock price prediction challanges, relation to news, why ML and Deep learning approach might work\n",
    "2. data munging and feature extraction\n",
    "   - scraping of news data from motleyfool.com\n",
    "   - getting the sentiment scores using the dictionary of positive and negative words\n",
    "   - designing a \"sentiment\" feature, word cloud for one POSITIVE and one NEGATIVE articles\n",
    "   - quandl.api to get the data, etc...\n",
    "3. method selection, evaluation, and comparison\n",
    "   - baseline classification methods, logistic regression, SVM, random forest\n",
    "   - feed forward neural nets, recurrent neural nets (description also)\n",
    "   - tuning the neural net parameters, etc.\n",
    "4. results and conclusion\n",
    "   - comparison of accuracy results, confusion matrix, ROC, PR, curves, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Munging and Feature Extraction\n",
    "\n",
    "1. www.motleyfool.com scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_ftp\n",
    "import requests_cache\n",
    "import lxml\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from scipy.misc import imread\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def motley_page_links(page):\n",
    "    \"\"\"\n",
    "    Given a page number, it returns all article links.\n",
    "    \n",
    "    Input: a page number (default = 1)\n",
    "    Output: a list with links on the given page\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(\n",
    "        'https://www.fool.com/search/solr.aspx?page={}&q=apple&sort=date&source=isesitbut0000001'.format(page))\n",
    "    response.raise_for_status()\n",
    "    html = response.text\n",
    "    parsed_html = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div_with_links = parsed_html.find_all(name = 'dl',\n",
    "                                         attrs = {'class' : 'results'})\n",
    "    links = []\n",
    "    for link in div_with_links[0].find_all('a', href = True):\n",
    "        links.append(link['href'])\n",
    "    \n",
    "    return links\n",
    "\n",
    "def motley_all_links(no_pages = 1):\n",
    "    \"\"\"\n",
    "    Given number of pages, it returns all the links \n",
    "    from \"no_pages\"\n",
    "    \n",
    "    Input: number of pages (default = 1)\n",
    "    Output: a list with links from the pages\n",
    "    \"\"\"\n",
    "    all_links = []\n",
    "    for page in range(1, (no_pages + 1)):\n",
    "        all_links.extend(motley_page_links(page))\n",
    "    \n",
    "    return all_links\n",
    "\n",
    "def motley_article_info(url):\n",
    "    \"\"\"\n",
    "    Given an article url, it returns title, date, content\n",
    "    and url of that article.\n",
    "    \n",
    "    Input: article url\n",
    "    Ouput: a dictionary with 'title', 'date',\n",
    "    'article', and 'url' as keys.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    html = response.text\n",
    "    parsed_html = BeautifulSoup(html, 'lxml')\n",
    "    content = parsed_html.find_all(name = 'div',\n",
    "                                      attrs = {'class' : 'full_article'})\n",
    "\n",
    "    date = parsed_html.find_all(name = 'div', attrs = {'class' : 'publication-date'})[0].text.strip()\n",
    "    title = parsed_html.find_all('h1')[0].text\n",
    "    article = ' '.join([t.text for t in content[0].find_all('p')])\n",
    "    \n",
    "    return {'title'   : title,\n",
    "            'date'    : date,\n",
    "            'article' : article,\n",
    "            'url'     : url}\n",
    "\n",
    "def motley_df(no_pages):\n",
    "    \"\"\"\n",
    "    Creates DataFrame for the articles in url\n",
    "    with author, text, title, and url as column\n",
    "    names.\n",
    "    \n",
    "    Input: A url, number of pages\n",
    "    Output: DataFrame with 4 columns: author,\n",
    "    text, title, and url.\n",
    "    \"\"\"\n",
    "    \n",
    "    #get all links in the specified number of pages\n",
    "    #from url\n",
    "    links = motley_all_links(no_pages)\n",
    "    \n",
    "    #create dataframe for each link and\n",
    "    #combine them into one dataframe\n",
    "    article_df = pd.DataFrame(index = [999999], columns=['article', 'date', 'title', 'url'])\n",
    "    for i, link in enumerate(links):\n",
    "        try:\n",
    "            append_to = pd.DataFrame(motley_article_info(link), index = [i])\n",
    "            article_df = article_df.append(append_to)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    article_df = article_df.drop(999999)\n",
    "    return article_df\n",
    "\n",
    "#df = motley_df(1000)\n",
    "#convert_to_csv(df, \"motleyfool.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "sentiment scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motley = pd.read_csv('motleyfool.csv')\n",
    "\n",
    "negative = pd.read_csv('negative-words.txt', sep = ' ', header = None)\n",
    "positive = pd.read_csv('positive-words.txt', sep=' ', header=None)\n",
    "\n",
    "def score_word(word):\n",
    "    \"\"\"\n",
    "    returns -1 if negative meaning, +1 if positive meaning,\n",
    "    else 0\n",
    "    \n",
    "    input: a word\n",
    "    ouput: -1, 0, or + 1\n",
    "    \"\"\"\n",
    "    if word.lower() in negative.values:\n",
    "        return -1\n",
    "    elif word.lower() in positive.values:\n",
    "        return +1\n",
    "    return 0\n",
    "\n",
    "def get_scores(article):\n",
    "    \"\"\"\n",
    "    returns sentiment scores for a given article\n",
    "    \n",
    "    input: an article\n",
    "    output: sentiment score\n",
    "    \"\"\"\n",
    "    wordsArticle = article.split(' ')\n",
    "    scores = [score_word(word) for word in wordsArticle]\n",
    "    return sum(scores)\n",
    "\n",
    "motley['sentiment'] = motley['article'].apply(get_scores)\n",
    "\n",
    "plt.hist(motley.sentiment, bins=50)\n",
    "plt.xlabel('sentiment scores')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Distribution of sentiment scores of articles');\n",
    "\n",
    "# motley.to_csv('motley_with_s_scores.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "merging data sets\n",
    "\n",
    "APPLE stock data was obtained using \"quandl.com\" API at \"https://www.quandl.com/api/v3/datasets/WIKI/AAPL.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aapl = pd.read_csv(path+'WIKI_PRICES_AAPL.csv')\n",
    "fool = pd.read_csv(path+'motley_with_s_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_df(stock_df, news_df, word):\n",
    "    \"\"\"\n",
    "    merges stock_df and news_df on \"date\"\n",
    "    column\n",
    "    \n",
    "    input: stock df, news df, word\n",
    "    output: merged df\n",
    "    \"\"\"\n",
    "    \n",
    "    stock_df['diff'] = stock_df['close']-stock_df['open']\n",
    "    news_df['Count'] = news_df['article'].apply(lambda x: x.count(word))\n",
    "    news_df.loc[news_df['Count'] <= 5, 'sentiment'] = 0\n",
    "    news_df['date'] = pd.to_datetime(news_df['date'])\n",
    "    news_df['date'] = news_df['date'].dt.strftime('%Y-%m-%d')\n",
    "    news_df = news_df.groupby(['date'], as_index = False).sum()\n",
    "    news_df = news_df[['date', 'sentiment', 'Count']]\n",
    "    merged_df = pd.merge(news_df, stock_df)\n",
    "    merged_df['bin_sentiment'] = pd.cut(merged_df['sentiment'], [-np.inf, -0.001, 0.001, np.inf], labels = [-1, 0, 1])\n",
    "    merged_df['bin_diff'] = pd.cut(merged_df['diff'], [-np.inf, -0.001, 0.001, np.inf], labels = [-1, 0, 1])\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df = format_df(aapl, fool, 'Apple')\n",
    "merged_df.head()\n",
    "#merged_df.to_csv('merged_df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Methods selection, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write more about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from  tensorflow.contrib.learn.python.learn.estimators.dnn  import DNNClassifier\n",
    "from tensorflow.contrib.layers import real_valued_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apple = pd.read_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Count</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ex-dividend</th>\n",
       "      <th>split_ratio</th>\n",
       "      <th>adj_open</th>\n",
       "      <th>adj_high</th>\n",
       "      <th>adj_low</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>adj_volume</th>\n",
       "      <th>diff</th>\n",
       "      <th>bin_sentiment</th>\n",
       "      <th>bin_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>53</td>\n",
       "      <td>133</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>590.14</td>\n",
       "      <td>601.0000</td>\n",
       "      <td>590.00</td>\n",
       "      <td>600.9600</td>\n",
       "      <td>10252400.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.229879</td>\n",
       "      <td>80.687900</td>\n",
       "      <td>79.211083</td>\n",
       "      <td>80.682530</td>\n",
       "      <td>71766800.0</td>\n",
       "      <td>10.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>15</td>\n",
       "      <td>177</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>601.80</td>\n",
       "      <td>604.4099</td>\n",
       "      <td>594.41</td>\n",
       "      <td>594.4100</td>\n",
       "      <td>13377300.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.795305</td>\n",
       "      <td>81.145700</td>\n",
       "      <td>79.803152</td>\n",
       "      <td>79.803152</td>\n",
       "      <td>93641100.0</td>\n",
       "      <td>-7.3900</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>40</td>\n",
       "      <td>134</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>595.25</td>\n",
       "      <td>597.2900</td>\n",
       "      <td>587.73</td>\n",
       "      <td>592.3300</td>\n",
       "      <td>10102300.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.915927</td>\n",
       "      <td>80.189810</td>\n",
       "      <td>78.906322</td>\n",
       "      <td>79.523900</td>\n",
       "      <td>70716100.0</td>\n",
       "      <td>-2.9200</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-05-08</td>\n",
       "      <td>31</td>\n",
       "      <td>109</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>588.25</td>\n",
       "      <td>594.4100</td>\n",
       "      <td>586.40</td>\n",
       "      <td>587.9900</td>\n",
       "      <td>8224900.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.418033</td>\n",
       "      <td>80.249678</td>\n",
       "      <td>79.168269</td>\n",
       "      <td>79.382931</td>\n",
       "      <td>57574300.0</td>\n",
       "      <td>-0.2600</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014-05-09</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>584.54</td>\n",
       "      <td>586.2500</td>\n",
       "      <td>580.33</td>\n",
       "      <td>585.5425</td>\n",
       "      <td>10414200.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.917156</td>\n",
       "      <td>79.148018</td>\n",
       "      <td>78.348775</td>\n",
       "      <td>79.052500</td>\n",
       "      <td>72899400.0</td>\n",
       "      <td>1.0025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date  sentiment  Count ticker    open      high     low  \\\n",
       "0           0  2014-05-05         53    133   AAPL  590.14  601.0000  590.00   \n",
       "1           1  2014-05-06         15    177   AAPL  601.80  604.4099  594.41   \n",
       "2           2  2014-05-07         40    134   AAPL  595.25  597.2900  587.73   \n",
       "3           3  2014-05-08         31    109   AAPL  588.25  594.4100  586.40   \n",
       "4           4  2014-05-09          3     67   AAPL  584.54  586.2500  580.33   \n",
       "\n",
       "      close      volume  ex-dividend  split_ratio   adj_open   adj_high  \\\n",
       "0  600.9600  10252400.0         0.00          1.0  79.229879  80.687900   \n",
       "1  594.4100  13377300.0         0.00          1.0  80.795305  81.145700   \n",
       "2  592.3300  10102300.0         0.00          1.0  79.915927  80.189810   \n",
       "3  587.9900   8224900.0         3.29          1.0  79.418033  80.249678   \n",
       "4  585.5425  10414200.0         0.00          1.0  78.917156  79.148018   \n",
       "\n",
       "     adj_low  adj_close  adj_volume     diff  bin_sentiment  bin_diff  \n",
       "0  79.211083  80.682530  71766800.0  10.8200              1         1  \n",
       "1  79.803152  79.803152  93641100.0  -7.3900              1        -1  \n",
       "2  78.906322  79.523900  70716100.0  -2.9200              1        -1  \n",
       "3  79.168269  79.382931  57574300.0  -0.2600              1        -1  \n",
       "4  78.348775  79.052500  72899400.0   1.0025              1         1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adj_volume</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bin_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>71766800.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>93641100.0</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-07</td>\n",
       "      <td>70716100.0</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-05-08</td>\n",
       "      <td>57574300.0</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-09</td>\n",
       "      <td>72899400.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  adj_volume  sentiment  bin_diff\n",
       "0  2014-05-05  71766800.0         53         1\n",
       "1  2014-05-06  93641100.0         15        -1\n",
       "2  2014-05-07  70716100.0         40        -1\n",
       "3  2014-05-08  57574300.0         31        -1\n",
       "4  2014-05-09  72899400.0          3         1"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = apple.copy()[['date', 'adj_volume', 'sentiment', 'bin_diff']]\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "InputDF = aapl.copy().drop('bin_diff', axis = 1)\n",
    "InputDF = InputDF.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = pd.qcut(apple['diff'], 2,labels=range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 1, ..., 0, 0, 1, 0, 1]\n",
       "Length: 779\n",
       "Categories (2, int64): [0 < 1]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_volume</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-05</th>\n",
       "      <td>71766800.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-06</th>\n",
       "      <td>93641100.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-07</th>\n",
       "      <td>70716100.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-08</th>\n",
       "      <td>57574300.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-09</th>\n",
       "      <td>72899400.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            adj_volume  sentiment\n",
       "date                             \n",
       "2014-05-05  71766800.0         53\n",
       "2014-05-06  93641100.0         15\n",
       "2014-05-07  70716100.0         40\n",
       "2014-05-08  57574300.0         31\n",
       "2014-05-09  72899400.0          3"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InputDF = InputDF.apply(lambda x:(x -x.mean())/x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_volume</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-05</th>\n",
       "      <td>1.255323</td>\n",
       "      <td>0.693098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-06</th>\n",
       "      <td>2.270155</td>\n",
       "      <td>-0.496574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-07</th>\n",
       "      <td>1.206577</td>\n",
       "      <td>0.286105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-08</th>\n",
       "      <td>0.596879</td>\n",
       "      <td>0.004340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-09</th>\n",
       "      <td>1.307868</td>\n",
       "      <td>-0.872260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            adj_volume  sentiment\n",
       "date                             \n",
       "2014-05-05    1.255323   0.693098\n",
       "2014-05-06    2.270155  -0.496574\n",
       "2014-05-07    1.206577   0.286105\n",
       "2014-05-08    0.596879   0.004340\n",
       "2014-05-09    1.307868  -0.872260"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 600\n",
    "xtrain, xtest = InputDF.iloc[:test_size, :], InputDF.iloc[test_size:, :]\n",
    "ytrain, ytest = label[:test_size], label[test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.73      0.55        83\n",
      "          1       0.48      0.21      0.29        96\n",
      "\n",
      "avg / total       0.46      0.45      0.41       179\n",
      "\n",
      "[[61 22]\n",
      " [76 20]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1216b1f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "res = svm.fit(xtrain, ytrain)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print (classification_report(ytest , res.predict(xtest)))\n",
    "print (confusion_matrix(ytest, res.predict(xtest)))\n",
    "plt.hist(ytest);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.66      0.54        83\n",
      "          1       0.53      0.33      0.41        96\n",
      "\n",
      "avg / total       0.50      0.49      0.47       179\n",
      "\n",
      "[[55 28]\n",
      " [64 32]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126312ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = logreg.fit(xtrain, ytrain)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print (classification_report(ytest , res.predict(xtest)))\n",
    "print (confusion_matrix(ytest, res.predict(xtest)))\n",
    "plt.hist(ytest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJalxBr0kNc6gl6TGGfSS1DiDXpIa978ARJ7jAbs6NQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126241908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(res.predict(xtest));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Tree Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(InputDF.columns)\n",
    "dropout=0.2\n",
    "hidden_1_size = 25\n",
    "hidden_2_size = 5\n",
    "num_classes = label.nunique()\n",
    "NUM_EPOCHS=20\n",
    "BATCH_SIZE=1\n",
    "lr=0.0001\n",
    "np.random.RandomState(52);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = (InputDF[:-test_size].values, label[:-test_size].values)\n",
    "train = (InputDF[-test_size:].values, label[-test_size:].values)\n",
    "NUM_TRAIN_BATCHES = int(len(train[0])/BATCH_SIZE)\n",
    "NUM_VAL_BATCHES = int(len(val[1])/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        self.input_data = tf.placeholder(dtype=tf.float32,shape=[None,num_features])\n",
    "        self.target_data = tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "        self.dropout_prob = tf.placeholder(dtype=tf.float32,shape=[])\n",
    "        with tf.variable_scope(\"ff\"):\n",
    "            droped_input = tf.nn.dropout(self.input_data,keep_prob=self.dropout_prob)\n",
    "            \n",
    "            layer_1 = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=hidden_1_size,\n",
    "                inputs=droped_input,\n",
    "            )\n",
    "            layer_2 = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=hidden_2_size,\n",
    "                inputs=layer_1,\n",
    "            )\n",
    "            self.logits = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=num_classes,\n",
    "                activation_fn =None,\n",
    "                inputs=layer_2,\n",
    "            )\n",
    "        with tf.variable_scope(\"loss\"):\n",
    "            \n",
    "            self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = self.logits, \n",
    "                                                                         labels = self.target_data)\n",
    "            mask = (1-tf.sign(1-self.target_data)) #Don't give credit for flat days\n",
    "            mask = tf.cast(mask,tf.float32)\n",
    "            self.loss = tf.reduce_sum(self.losses)\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "            opt = tf.train.AdamOptimizer(lr)\n",
    "            gvs = opt.compute_gradients(self.loss)\n",
    "            self.train_op = opt.apply_gradients(gvs, global_step=global_step)\n",
    "        \n",
    "        with tf.name_scope(\"predictions\"):\n",
    "            self.probs = tf.nn.softmax(self.logits)\n",
    "            self.predictions = tf.argmax(self.probs, 1)\n",
    "            correct_pred = tf.cast(tf.equal(self.predictions, tf.cast(self.target_data,tf.int64)),tf.float64)\n",
    "            self.accuracy = tf.reduce_mean(correct_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-468-ae0dfdb5ea85>:7: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step - 600 loss - 419.2093040943146 acc - 1.0\n",
      "step - 1200 loss - 417.2555048465729 acc - 1.0\n",
      "step - 1800 loss - 417.2346202135086 acc - 1.0\n",
      "step - 2400 loss - 416.2016576528549 acc - 1.0\n",
      "step - 3000 loss - 415.71979638934135 acc - 1.0\n",
      "step - 3600 loss - 414.8969846665859 acc - 1.0\n",
      "step - 4200 loss - 415.8810990154743 acc - 1.0\n",
      "step - 4800 loss - 415.78498965501785 acc - 1.0\n",
      "step - 5400 loss - 414.56457966566086 acc - 1.0\n",
      "step - 6000 loss - 414.3590054810047 acc - 1.0\n",
      "step - 6600 loss - 414.5243852734566 acc - 1.0\n",
      "step - 7200 loss - 413.4972666800022 acc - 1.0\n",
      "step - 7800 loss - 414.7007949948311 acc - 1.0\n",
      "step - 8400 loss - 415.1870813071728 acc - 1.0\n",
      "step - 9000 loss - 413.92336907982826 acc - 0.0\n",
      "step - 9600 loss - 414.7711333334446 acc - 1.0\n",
      "step - 10200 loss - 413.981097638607 acc - 0.0\n",
      "step - 10800 loss - 413.9152930676937 acc - 1.0\n",
      "step - 11400 loss - 413.7775710821152 acc - 0.0\n",
      "step - 12000 loss - 414.0470404922962 acc - 0.0\n",
      "done training\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    model = Model()\n",
    "    input_ = train[0]\n",
    "    target = train[1]\n",
    "    losses = []\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess.run([init])\n",
    "        epoch_loss =0\n",
    "        for e in range(NUM_EPOCHS):\n",
    "            if epoch_loss >0 and epoch_loss <1:\n",
    "                break\n",
    "            epoch_loss =0\n",
    "            for batch in range(0,NUM_TRAIN_BATCHES):\n",
    "                \n",
    "                start = batch*BATCH_SIZE\n",
    "                end = start + BATCH_SIZE \n",
    "                feed = {\n",
    "                    model.input_data:input_[start:end],\n",
    "                    model.target_data:target[start:end],\n",
    "                    model.dropout_prob:0.9\n",
    "                            }\n",
    "                \n",
    "                _,loss,acc = sess.run(\n",
    "                    [\n",
    "                        model.train_op,\n",
    "                        model.loss,\n",
    "                        model.accuracy,\n",
    "                    ]\n",
    "                    ,feed_dict=feed\n",
    "                )\n",
    "                epoch_loss+=loss\n",
    "            losses.append(epoch_loss)\n",
    "            print('step - {0} loss - {1} acc - {2}'.format((1+batch+NUM_TRAIN_BATCHES*e),epoch_loss,acc))\n",
    "                \n",
    "        \n",
    "        print('done training')\n",
    "        final_preds =np.array([])\n",
    "        final_probs =None\n",
    "        for batch in range(0,NUM_VAL_BATCHES):\n",
    "            \n",
    "                start = batch*BATCH_SIZE\n",
    "                end = start + BATCH_SIZE \n",
    "                feed = {\n",
    "                    model.input_data:val[0][start:end],\n",
    "                    model.target_data:val[1][start:end],\n",
    "                    model.dropout_prob:1\n",
    "                            }\n",
    "                \n",
    "                acc,preds,probs = sess.run(\n",
    "                    [\n",
    "                        model.accuracy,\n",
    "                        model.predictions,\n",
    "                        model.probs\n",
    "                    ]\n",
    "                    ,feed_dict=feed\n",
    "                )\n",
    "                print(acc)\n",
    "                final_preds = np.concatenate((final_preds,preds),axis=0)\n",
    "                if final_probs is None:\n",
    "                    final_probs = probs\n",
    "                else:\n",
    "                    final_probs = np.concatenate((final_probs,probs),axis=0)\n",
    "        prediction_conf = final_probs[np.argmax(final_probs, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQZiZWS4nCDMzy+UEYWZmuZwgzMws1/8HfSIoOQC/bcQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120ab56d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.linspace(0, 1, len(losses)), losses);\n",
    "plt.title('Validation loss with epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.xlabel('epoch progression');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.51      0.47        83\n",
      "          1       0.51      0.44      0.47        96\n",
      "\n",
      "avg / total       0.47      0.47      0.47       179\n",
      "\n",
      "[[42 41]\n",
      " [54 42]]\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(ytest.values, final_preds))\n",
    "print (confusion_matrix(ytest, final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers.python.layers.initializers import xavier_initializer\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "RNN_HIDDEN_SIZE=4\n",
    "FIRST_LAYER_SIZE=50\n",
    "SECOND_LAYER_SIZE=10\n",
    "NUM_LAYERS=2\n",
    "BATCH_SIZE=1\n",
    "NUM_EPOCHS=25\n",
    "lr=0.0003\n",
    "NUM_TRAIN_BATCHES = int(len(train[0])/BATCH_SIZE)\n",
    "NUM_VAL_BATCHES = int(len(val[1])/BATCH_SIZE)\n",
    "ATTN_LENGTH=30\n",
    "beta=0\n",
    "np.random.RandomState(52);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel():\n",
    "    def __init__(self):\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        self.input_data = tf.placeholder(dtype=tf.float32,shape=[BATCH_SIZE,num_features])\n",
    "        self.target_data = tf.placeholder(dtype=tf.int32,shape=[BATCH_SIZE])\n",
    "        self.dropout_prob = tf.placeholder(dtype=tf.float32,shape=[])\n",
    "        \n",
    "        def makeGRUCells():\n",
    "            base_cell = rnn.GRUCell(num_units=RNN_HIDDEN_SIZE,) \n",
    "            layered_cell = rnn.MultiRNNCell([base_cell] * NUM_LAYERS,state_is_tuple=False) \n",
    "            attn_cell =tf.contrib.rnn.AttentionCellWrapper(cell=layered_cell,attn_length=ATTN_LENGTH,state_is_tuple=False)\n",
    "            return attn_cell\n",
    "        \n",
    "        self.gru_cell = makeGRUCells()\n",
    "        self.zero_state = self.gru_cell.zero_state(1, tf.float32)\n",
    "        \n",
    "        self.start_state = tf.placeholder(dtype=tf.float32,shape=[1,self.gru_cell.state_size])\n",
    "        \n",
    "        \n",
    "\n",
    "        with tf.variable_scope(\"ff\",initializer=xavier_initializer(uniform=False)):\n",
    "            droped_input = tf.nn.dropout(self.input_data,keep_prob=self.dropout_prob)\n",
    "            \n",
    "            layer_1 = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=FIRST_LAYER_SIZE,\n",
    "                inputs=droped_input,\n",
    "                \n",
    "            )\n",
    "            layer_2 = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=RNN_HIDDEN_SIZE,\n",
    "                inputs=layer_1,\n",
    "                \n",
    "            )\n",
    "            \n",
    "        \n",
    "        split_inputs = tf.reshape(droped_input,shape=[1,BATCH_SIZE,num_features],name=\"reshape_l1\") # Each item in the batch is a time step, iterate through them\n",
    "        split_inputs = tf.unstack(split_inputs,axis=1,name=\"unpack_l1\")\n",
    "        states =[]\n",
    "        outputs =[]\n",
    "        with tf.variable_scope(\"rnn\",initializer=xavier_initializer(uniform=False)) as scope:\n",
    "            state = self.start_state\n",
    "            for i, inp in enumerate(split_inputs):\n",
    "                if i >0:\n",
    "                    scope.reuse_variables()\n",
    "                \n",
    "                output, state = self.gru_cell(inp, state)\n",
    "                states.append(state)\n",
    "                outputs.append(output)\n",
    "        self.end_state = states[-1]\n",
    "        outputs = tf.stack(outputs,axis=1) # Pack them back into a single tensor\n",
    "        outputs = tf.reshape(outputs,shape=[BATCH_SIZE,RNN_HIDDEN_SIZE])\n",
    "        self.logits = tf.contrib.layers.fully_connected(\n",
    "            num_outputs=num_classes,\n",
    "            inputs=outputs,\n",
    "            activation_fn=None\n",
    "        )\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"loss\"):\n",
    "            self.penalties =    tf.reduce_sum([beta*tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n",
    "\n",
    "            \n",
    "            self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = self.logits,\n",
    "                                                                         labels = self.target_data)\n",
    "            self.loss = tf.reduce_sum(self.losses + beta*self.penalties)\n",
    "        \n",
    "        with tf.name_scope(\"train_step\"):\n",
    "            opt = tf.train.AdamOptimizer(lr)\n",
    "            gvs = opt.compute_gradients(self.loss)\n",
    "            self.train_op = opt.apply_gradients(gvs, global_step=global_step)\n",
    "        \n",
    "        with tf.name_scope(\"predictions\"):\n",
    "            probs = tf.nn.softmax(self.logits)\n",
    "            self.predictions = tf.argmax(probs, 1)\n",
    "            correct_pred = tf.cast(tf.equal(self.predictions, tf.cast(self.target_data,tf.int64)),tf.float64)\n",
    "            self.accuracy = tf.reduce_mean(correct_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.rnn_cell.AttentionCellWrapper object at 0x1210e60b8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "step - 0 loss - 417.21387165784836 acc - 0.0\n",
      "step - 1 loss - 416.0871697664261 acc - 0.0\n",
      "step - 2 loss - 415.7393709421158 acc - 0.0\n",
      "step - 3 loss - 416.2393338084221 acc - 0.0\n",
      "step - 4 loss - 415.31454586982727 acc - 0.0\n",
      "step - 5 loss - 416.07181894779205 acc - 1.0\n",
      "step - 6 loss - 415.53357696533203 acc - 0.0\n",
      "step - 7 loss - 415.31331557035446 acc - 0.0\n",
      "step - 8 loss - 415.38470923900604 acc - 0.0\n",
      "step - 9 loss - 415.98950189352036 acc - 0.0\n",
      "step - 10 loss - 414.35794323682785 acc - 0.0\n",
      "step - 11 loss - 414.7595503926277 acc - 1.0\n",
      "step - 12 loss - 415.2831164598465 acc - 0.0\n",
      "step - 13 loss - 416.1695525050163 acc - 0.0\n",
      "step - 14 loss - 414.42500281333923 acc - 1.0\n",
      "step - 15 loss - 415.21704733371735 acc - 1.0\n",
      "step - 16 loss - 415.33552449941635 acc - 1.0\n",
      "step - 17 loss - 414.18447881937027 acc - 1.0\n",
      "step - 18 loss - 415.9529753923416 acc - 1.0\n",
      "step - 19 loss - 414.1148049235344 acc - 0.0\n",
      "step - 20 loss - 415.9385293126106 acc - 1.0\n",
      "step - 21 loss - 414.4861587882042 acc - 1.0\n",
      "step - 22 loss - 414.63779467344284 acc - 0.0\n",
      "step - 23 loss - 416.98986756801605 acc - 0.0\n",
      "step - 24 loss - 414.942509829998 acc - 0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    model = RNNModel()\n",
    "    input_ = train[0]\n",
    "    target = train[1]\n",
    "    losses = []\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run([init])\n",
    "        loss = 2000\n",
    "        \n",
    "        for e in range(NUM_EPOCHS):\n",
    "            state = sess.run(model.zero_state)\n",
    "            epoch_loss =0\n",
    "            for batch in range(0,NUM_TRAIN_BATCHES):\n",
    "                start = batch*BATCH_SIZE\n",
    "                end = start + BATCH_SIZE \n",
    "                feed = {\n",
    "                    model.input_data:input_[start:end],\n",
    "                    model.target_data:target[start:end],\n",
    "                    model.dropout_prob:0.5,\n",
    "                    model.start_state:state\n",
    "                            }\n",
    "                _,loss,acc,state = sess.run(\n",
    "                    [\n",
    "                        model.train_op,\n",
    "                        model.loss,\n",
    "                        model.accuracy,\n",
    "                        model.end_state\n",
    "                    ]\n",
    "                    ,feed_dict=feed\n",
    "                )\n",
    "                epoch_loss+=loss\n",
    "            losses.append(epoch_loss)\n",
    "            print('step - {0} loss - {1} acc - {2}'.format((e),epoch_loss,acc))\n",
    "        final_preds =np.array([])\n",
    "        for batch in range(0,NUM_VAL_BATCHES):\n",
    "                start = batch*BATCH_SIZE\n",
    "                end = start + BATCH_SIZE \n",
    "                feed = {\n",
    "                    model.input_data:val[0][start:end],\n",
    "                    model.target_data:val[1][start:end],\n",
    "                    model.dropout_prob:1,\n",
    "                    model.start_state:state\n",
    "                            }\n",
    "                acc,preds,state = sess.run(\n",
    "                    [\n",
    "                        model.accuracy,\n",
    "                        model.predictions,\n",
    "                        model.end_state\n",
    "                    ]\n",
    "                    ,feed_dict=feed\n",
    "                )\n",
    "                print(acc)\n",
    "                assert len(preds) == BATCH_SIZE\n",
    "                final_preds = np.concatenate((final_preds,preds),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgwESVLDQJAkAfD/AEB5D3d/4KmNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12393e080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.linspace(0, 1, len(losses)), losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.39      0.42        83\n",
      "          1       0.53      0.59      0.56        96\n",
      "\n",
      "avg / total       0.49      0.50      0.49       179\n",
      "\n",
      "[[32 51]\n",
      " [39 57]]\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(ytest.values, final_preds))\n",
    "print (confusion_matrix(ytest, final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
